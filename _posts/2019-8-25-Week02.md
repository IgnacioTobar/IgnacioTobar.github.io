---
layout: post
title: Week 02
---

## Scalable collaborative filtering approaches for large recommender systems

The paper is about Collaborative filtering (CF), specifically focusing in Matrix Factorization (MF) algorithms. It proposes various MF based techniques plus a neighbor correction method for MF to improve it even further. All this with the objective to develop scalable and efficient approaches for CF, that compare favorably with existing ones.

The most commendable thing about this paper is how thoroughly and extensively it explained and tested each and every variation of the algorithm (even in multiple datasets) to evaluate how much it actually improves its performance.

Special attention must be given to the section about Neighbor Based Correction, as it mixes MF techniques (model-based) with memory-based techniques: Neighbor based (NB) approaches use the fact that similar users rate similar items similarly. The intuition of this method is that at prediction time: a correction term is added based on the similarity of items rated by other similar users, as they should rate items similarly to the original user. 


## Collaborative filtering for implicit feedback datasets

The paper discuss about implicit feedback, its differences with the usual explicit feedback scheme and its unique characteristics.
Unlike explicit feedback, it is hard to reliably infer which items a user did not like, and absence of rating could mean the user did not like the item, that the user hasn't interact with it *yet*, or that he simply doesn't know it exists. How to deal with this missing data is one of the principal differences between explicit and implicit feedback.


The paper deals with the differences of this data in the following way: while the values of explicit feedback indicates *preference*, implicit feedback indicates *confidence*. The more frequent an observation is, the more likely it reflects the user's tastes.  
The paper provides a latent factor algorithm that uses this idea of confidence over preference.   
In my opinion the biggest take-away of this algorithm, is that it also allows for explainability of its decisions (a rarity among latent factor models), this helps in improving the usersâ€™ trust in the system and their ability to put recommendations in the right perspective.
