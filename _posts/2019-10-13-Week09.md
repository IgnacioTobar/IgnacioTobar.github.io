---
layout: post
title: Week 09
---

## The Effect of Explanations and Algorithmic Accuracy on Visual Recommender Systems of Artistic Images

The paper is about trying to explain the decision of different content based recommender systems to the users, and how this explanation affects their satisfaction with the system.  

The paper tests 2 different models: a Deep Neural Network (DNN), and an Attractiveness Visual Features (AVF) Algorithm, which uses handcrafted features of the image to recommend. For these 2 models, the paper tests 3 different interfaces: no explanation at all, explaining using the top 3 most similar images and based on their visual features (AVF only).  

The results of the tests show that while AVF recommended more diverse images (a good thing), in all the other metrics (Explainability, Relevance, Satisfaction, Trust, etc.), the DNN performed much better. Overall, the study shows that explaining the recommendations has a positive effect on the users.  

Something I would criticize the paper about, is that because the DNN doesn't have human interpretable features, it was only evaluated with either: no explanation, or explanation using top 3 images. Common sense would dictate that any (reasonable) explanation is better than no explanation at all, so it's hard to evaluate how relevant this result is. It would be interesting to try to devise different ways to explain the DNN (maybe something related to the weights of the network or what part of the image the model focused on, for example).

